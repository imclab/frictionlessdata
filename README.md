# Building a frictionless data ecosystem

# The Vision

Story: there's too much friction working with data - friction getting data, friction processing data, friction sharing data.

This friction stops people doing stuff - stops them creating, sharing, collaborating, using (especially amongst distributed communities). It kills the cycles of find, improve, share that would make for a real open data ecosystem.

We think getting some key pieces in place can reduce friction enough to lead to a step-change (revolution) in how the (open) data ecosystem operates with massively improved quality, utilization and sharing of data.

We think that there's a multiplier here: relatively small changes can have big effects. This is because Network effects matter: the utility of a particular standard, pattern or even tool will depend on how many other people are using it. Creating a critical mass of use around the tooling and standards will be critical. But after working on these issues for nearly a decade we think the time is right.

## What do we want to do?

There are 3 broad areas that work needs to be done in:

- Infrastructure and tools
- Patterns and standards
- Outreach and adoption

[Aside] this last is especially important: as we emphasized, network effects matter and currently the ecosystem very balkanized (there's the R folks over here, the data portals over there, the map-reduce folks over there ...).

Being more specific we are focusing our activity in the following "projects":

### Data Package standard - the "Data Package" project

- The basic pattern for preparing data
- Mininum viable standard
- Extensible to tabular and geodata
- Documentation and complementary tools are essential

### Publish and "Install" - the "Registry and Tool" project

- Integrate (plugins etc) - its got to be incredibly easy to use "packaged" data
- The value add e.g. dependencies
- Data more diverse than code so more work here

### Provide essential data - the "Datasets Project"

- Helps to socialize and demonstrate data package concepts
- Source of data to use (high quality, needed and useful)

### Process, clean, fix, store - the "Infrastructure Project"

- More miscellaneous than other "projects" but important
- Process, cleaning storing etc are tied together (storage and fixing are related - versioning, patching etc)
- High quality data is important (little incentive to use or improve if most data is bad data)

## Principles

From first Frictionless Data post

* Lightweight
* Simple
* Web oriented
* Distributed
* Collaborative

## Stories and Analogies

* with logistics for ingredients for cooking (cf [Frictionless Post][friction]).
* Analogy with libraries and packaging in code

### What an Ecosystem Looks Like

From [Building the (Open) Data Ecosystem][ecosystem]

<img src="http://farm6.staticflickr.com/5149/5564991102_fcf972d056_z.jpg" alt="" style="max-width: 48%; max-height: 400px;" />

<img src="http://farm6.static.flickr.com/5296/5564414863_bafa3e82b7.jpg" alt="" style="max-width: 48%; max-height: 400px;" />

From @maxogden's [Dat Project][dat]

[dat]: https://github.com/maxogden/dat

<img src="https://github.com/maxogden/dat/raw/master/img/dat-diagram.png" />

### Data Pipelines

Data Pipeline Overview from School of Data Workshop May 2012 (Drawing by Stefan Urbanek)

<img src="http://farm8.staticflickr.com/7073/7177017539_f8bfce4075_c.jpg" alt="" />

Data Pipeline Detail from School of Data Workshop May 2012 (Drawing by Stefan Urbanek)

<img src="http://farm8.staticflickr.com/7235/7176971829_753699235a_b.jpg" alt="" />

## References

* [Frictionless Data: making it radically easier to get stuff done with data][friction]
* [Building the (Open) Data Ecosystem][ecosystem]

[friction]: http://blog.okfn.org/2013/04/24/frictionless-data-making-it-radically-easier-to-get-stuff-done-with-data/
[ecosystem]: http://blog.okfn.org/2011/03/31/building-the-open-data-ecosystem/

